<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FlowMo: Variance-Based Flow Guidance for Coherent Motion in Video Generation">
  <meta name="keywords" content="Video generation, Motion coherence, Diffusion models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FlowMo: Variance-Based Flow Guidance for Coherent Motion in Video Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <style>
    .hero {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
    }

    .publication-title {
      font-size: 2.5rem !important;
      font-weight: 700;
      margin-bottom: 1.5rem;
      text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }

    .publication-authors {
      margin-bottom: 1rem;
    }

    .publication-authors a {
      color: #fff;
      text-decoration: none;
      transition: all 0.3s ease;
    }

    .publication-authors a:hover {
      color: #ffd700;
      text-shadow: 1px 1px 2px rgba(0,0,0,0.5);
    }

    .button.is-dark {
      background-color: rgba(0,0,0,0.8);
      border: 2px solid rgba(255,255,255,0.3);
      transition: all 0.3s ease;
    }

    .button.is-dark:hover {
      background-color: rgba(255,255,255,0.2);
      border-color: #ffd700;
      transform: translateY(-2px);
    }

    .video-grid {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 15px;
      max-width: 800px; /* Reduced from 1200px */
      margin: 0 auto;
    }

    .video-item-custom {
      text-align: center;
    }

    .video-item-custom video {
      width: 100%;
      height: auto;
      border-radius: 8px;
    }

    .video-caption {
      margin-top: 10px;
      font-size: 14px;
      color: #666;
    }

    .video-title {
      margin-bottom: 8px; /* Reduced from 10px */
      font-weight: bold;
      text-align: center;
      font-size: 0.9rem; /* Made text smaller */
    }

    .comparison-section {
      margin: 40px 0;
    }

    .motivation-grid {
      display: grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 10px;
      max-width: 1000px;
      margin: 20px auto;
    }

    .motivation-grid video {
      width: 100%;
      height: auto;
      border-radius: 4px;
    }

    .center-video {
      max-width: 600px;
      margin: 20px auto;
      text-align: center;
    }

    .center-image {
      max-width: 500px;
      margin: 20px auto;
      text-align: center;
    }

    /* Carousel specific styles - making cards smaller */
    .carousel {
      max-width: 900px; /* Reduced from implicit full width */
      margin: 0 auto;
    }

    .carousel-item {
      display: flex;
      gap: 12px; /* Reduced gap between videos */
      padding: 10px; /* Reduced padding */
    }

    .video-item {
      flex: 1;
      text-align: center;
    }

    .video-item video {
      width: 100%;
      max-width: 350px; /* Set maximum width for videos */
      height: auto;
      border-radius: 8px;
      box-shadow: 0 4px 8px rgba(0,0,0,0.1);
      transition: transform 0.3s ease;
    }

    .video-item video:hover {
      transform: scale(1.02);
    }

    /* Navigation arrows styling */
    .carousel .carousel-nav-left,
    .carousel .carousel-nav-right {
      background: rgba(0,0,0,0.7);
      color: white;
      border: none;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.3s ease;
    }

    .carousel .carousel-nav-left:hover,
    .carousel .carousel-nav-right:hover {
      background: rgba(0,0,0,0.9);
      transform: scale(1.1);
    }

    .section {
      padding: 3rem 1.5rem;
    }

    .title.is-3 {
      color: #363636;
      margin-bottom: 2rem;
    }

    .content {
      font-size: 1.1rem;
      line-height: 1.7;
    }

    .content p {
      margin-bottom: 1.5rem;
    }

    /* Mobile responsiveness */
    @media (max-width: 768px) {
      .carousel-item {
        flex-direction: column;
        gap: 15px;
      }
      
      .video-item video {
        max-width: 100%;
      }
      
      .video-grid {
        grid-template-columns: 1fr;
        max-width: 400px;
      }
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FlowMo: Variance-Based Flow Guidance for Coherent Motion in Video Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=A31XmP0AAAAJ">Ariel Shaulov*</a><sup></sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=1ebLvzgAAAAJ&hl=en&oi=ao">Itay Hazan*</a><sup></sup>,</span>
            <span class="author-block">
              <a href="http://www.cs.tau.ac.il/~wolf/">Lior Wolf</a><sup></sup>,</span>
            <span class="author-block">
              <a href="https://hila-chefer.github.io/">Hila Chefer</a><sup></sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup></sup>School of Computer Science, Tel Aviv University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Text-to-video diffusion models are notoriously limited in their ability to model temporal
            aspects such as motion, physics, and dynamic interactions. Existing approaches address this
            limitation by retraining the model or introducing external conditioning signals to enforce
            temporal consistency. In this work, we explore whether a meaningful temporal representation can
            be extracted directly from the predictions of a pre-trained model without any additional
            training or auxiliary inputs. We introduce <strong>FlowMo</strong>, a novel training-free
            guidance method that enhances motion coherence using only the model's own predictions in each
            diffusion step.
          </p>
          <p>
            FlowMo first derives an appearance-debiased temporal representation by measuring the distance
            between latents corresponding to consecutive frames. This highlights the implicit temporal
            structure predicted by the model.
            It then estimates motion coherence by measuring the patch-wise variance across the temporal
            dimension, and guides the model to reduce this variance dynamically during sampling. Extensive
            experiments across multiple text-to-video models demonstrate that FlowMo significantly improves
            motion coherence without sacrificing visual quality or prompt alignment, offering an effective
            plug-and-play solution for enhancing the temporal fidelity of pre-trained video diffusion
            models.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<!-- Qualitative Comparison Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Qualitative Comparison: FlowMo vs. Base Models</h2>
    
    <div class="content">
      <p class="has-text-centered">
        As mentioned in the paper, <strong>FlowMo is a novel training-free guidance method that enhances motion
        coherence</strong>. In this section, we provide an
        <strong>apples-to-apples</strong> qualitative comparison showing the impact of FlowMo on the base model
        (Wan2.1-1.3B, CogVideoX-5B). The comparisons are conducted with the same random seed on diverse prompts
        that capture a variety of motion types.
        <strong>Use the arrows to navigate through the results.</strong>
      </p>
    </div>

    <!-- Wan2.1-1.3B Results -->
    <h3 class="title is-4 has-text-centered comparison-section">Wan2.1-1.3B</h3>
    
    <div class="carousel" id="wan-carousel">
      <div class="carousel-container">
        <div class="carousel-item">
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/4287f5/ffffff?text=Video+1A" type="video/mp4">
              </video>
              <div class="video-title">A boy with glasses flying a kite in a grassy field.</div>
          </div>
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/f54242/ffffff?text=Video+1B" type="video/mp4">
              </video>
              <div class="video-title">A woman performing a challenging exercise.</div>
          </div>
        </div>
        
        <div class="carousel-item">
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/42f554/ffffff?text=Video+2A" type="video/mp4">
              </video>
              <div class="video-title">A dolphin jumping out of ocean waves.</div>
          </div>
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/f5a742/ffffff?text=Video+2B" type="video/mp4">
              </video>
              <div class="video-title">A ninja flipping through a bamboo forest.</div>
          </div>
        </div>

        <div class="carousel-item">
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/a742f5/ffffff?text=Video+3A" type="video/mp4">
              </video>
              <div class="video-title">A person rowing a boat across a misty lake.</div>
          </div>
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/f542a7/ffffff?text=Video+3B" type="video/mp4">
              </video>
              <div class="video-title">A roulette wheel in a dimly lit room or casino floor.</div>
          </div>
        </div>
      </div>
      
      <button class="carousel-nav-left" onclick="prevSlide('wan-carousel')">
        <i class="fas fa-chevron-left"></i>
      </button>
      <button class="carousel-nav-right" onclick="nextSlide('wan-carousel')">
        <i class="fas fa-chevron-right"></i>
      </button>
    </div>

    <!-- CogVideoX-5B Results -->
    <h3 class="title is-4 has-text-centered comparison-section">CogVideoX-5B</h3>
    
    <div class="carousel" id="cog-carousel">
      <div class="carousel-container">
        <div class="carousel-item">
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/5442f5/ffffff?text=Cog+1A" type="video/mp4">
              </video>
              <div class="video-title">A violinist performing a solo on stage.</div>
          </div>
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/42f5d4/ffffff?text=Cog+1B" type="video/mp4">
              </video>
              <div class="video-title">A pair of flamingos wading through shallow water.</div>
          </div>
        </div>

        <div class="carousel-item">
            <div class="video-item">
                <video loading="lazy" autoplay loop muted>
                    <source src="https://via.placeholder.com/400x300/d442f5/ffffff?text=Cog+2A" type="video/mp4">
                </video>
                <div class="video-title">A ballerina leaping through the air.</div>
            </div>
            <div class="video-item">
                <video loading="lazy" autoplay loop muted>
                    <source src="https://via.placeholder.com/400x300/f5d442/ffffff?text=Cog+2B" type="video/mp4">
                </video>
                <div class="video-title">A deer leaping over a fallen log.</div>
            </div>
        </div>
      </div>
      
      <button class="carousel-nav-left" onclick="prevSlide('cog-carousel')">
        <i class="fas fa-chevron-left"></i>
      </button>
      <button class="carousel-nav-right" onclick="nextSlide('cog-carousel')">
        <i class="fas fa-chevron-right"></i>
      </button>
    </div>
  </div>
</section>

<!-- FlowMo vs FreeInit Comparison -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Qualitative Comparison: FlowMo vs. FreeInit</h2>
    
    <div class="content">
      <p class="has-text-centered">
        As mentioned in the paper, <strong>we compare FlowMo with FreeInit</strong>, a method originally
        designed for UNet-based DDPM/DDIM models that suffer from temporal artifacts due to signal-to-noise
        ratio (SNR) discrepancies between training and inference. These artifacts often result in
        inconsistencies across frames (e.g., identity or background shifts).
        In contrast, FlowMo operates on modern Transformer-based models trained with Flow Matching (FM), which
        offer greater temporal consistency due to stronger architectures and training on large-scale data. For a
        fair comparison, we adapted FreeInit to FM-based DiT models by applying its re-noising strategy to
        initialize low-frequency components.
        <strong>Use the arrows to navigate through the results.</strong>
      </p>
    </div>

    <div class="carousel" id="freeinit-carousel">
      <div class="carousel-container">
        <div class="carousel-item">
            <div class="video-item">
                <video loading="lazy" autoplay loop muted>
                    <source src="https://via.placeholder.com/400x300/42a7f5/ffffff?text=Free+1A" type="video/mp4">
                </video>
                <div class="video-title">Athletic man doing gymnastics on a horizontal bar.</div>
            </div>
            <div class="video-item">
                <video loading="lazy" autoplay loop muted>
                    <source src="https://via.placeholder.com/400x300/a7f542/ffffff?text=Free+1B" type="video/mp4">
                </video>
                <div class="video-title">Young adult male doing a handstand on the beach.</div>
            </div>
        </div>

        <div class="carousel-item">
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/f57542/ffffff?text=Free+2A" type="video/mp4">
              </video>
              <div class="video-title">A small dog playing with a red ball on a hardwood floor.</div>
          </div>
          <div class="video-item">
              <video loading="lazy" autoplay loop muted>
                  <source src="https://via.placeholder.com/400x300/7542f5/ffffff?text=Free+2B" type="video/mp4">
              </video>
              <div class="video-title">A man jumping rope on a dark stage.</div>
          </div>
        </div>
      </div>
      
      <button class="carousel-nav-left" onclick="prevSlide('freeinit-carousel')">
        <i class="fas fa-chevron-left"></i>
      </button>
      <button class="carousel-nav-right" onclick="nextSlide('freeinit-carousel')">
        <i class="fas fa-chevron-right"></i>
      </button>
    </div>
  </div>
</section>

<!-- Motivation for FlowMo Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Motivation for FlowMo</h2>
    
    <div class="content">
      <p>
        FlowMo arose from the observation that videos with coherent and incoherent motion exhibit separation in
        a measure we defined as <strong>Patch-Wise Variance</strong>. Given a tensor, we first compute the
        â„“<sub>1</sub>-distance between consecutive latent frames to eliminate their common appearance
        information and get a debiased motion representation. We then compute patch-wise temporal variance, and
        finally take its mean value across channels.
      </p>

      <div class="center-video">
        <video autoplay loop muted playsinline style="max-width: 100%; border-radius: 8px;">
          <source src="https://via.placeholder.com/600x400/333333/ffffff?text=Method+Video" type="video/mp4">
        </video>
        <p class="video-caption">Patch-Wise Variance of a Latent Video</p>
      </div>

      <p>
        After examining the patch-wise variance of the model's prediction when generating videos with coherent
        and incoherent motion, we found that the model's predictions for coherent motion consistently exhibited
        lower patch-wise variance compared to those for incoherent motion, as seen in the figure below.
        Intuitively, in videos with smooth and consistent motion, object trajectories evolve gradually,
        resulting in lower temporal variance. In contrast, incoherent motion introduces abrupt changes,
        manifesting as larger fluctuations and higher patch-wise variance in the latent predictions.
      </p>

      <div class="center-image">
        <img src="https://via.placeholder.com/500x300/666666/ffffff?text=Variance+Chart" alt="Patch-wise variance" style="max-width: 100%; border-radius: 8px;">
        <p class="video-caption">Patch-Wise Variance Analysis</p>
      </div>

      <p>
        We have therefore proposed to use this measure to guide the model to reduce the patch-wise variance
        during sampling, thus encouraging it to produce a prediction which is more likely to demonstrate
        coherent motion. After each timestep of the first 12 timesteps, <strong>FlowMo</strong> minimizes the 
        maximum patch-wise variance of the model's prediction, which results in an adjusted latent for the next
        timestep. We chose the first 12 timesteps because we found that coarse spatial information is determined 
        in the first steps (0-4) and motion is determined at around steps 5-8 (and refined later), as seen in 
        the figures below.
      </p>

      <div class="motivation-grid">
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/ff6b6b/ffffff?text=T0" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/4ecdc4/ffffff?text=T1" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/45b7d1/ffffff?text=T2" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/f9ca24/ffffff?text=T3" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/f0932b/ffffff?text=T4" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/eb4d4b/ffffff?text=T5" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/6ab04c/ffffff?text=T6" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/130f40/ffffff?text=T7" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/9980fa/ffffff?text=T8" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/e056fd/ffffff?text=T9" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/ff9ff3/ffffff?text=T10" type="video/mp4"></video></div>
        <div><video autoplay loop muted playsinline><source src="https://via.placeholder.com/200x150/54a0ff/ffffff?text=T11" type="video/mp4"></video></div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p>If you find this project useful for your research, please cite the following:
    </p>
    <pre><code>@article{flowmo2024,
  title={FlowMo: Variance-Based Flow Guidance for Coherent Motion in Video Generation},
  author={Shaulov, Ariel and Hazan, Itay and Wolf, Lior and Chefer, Hila},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2024}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/arielshaulov" class="external-link">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the
            <a rel="Nerfies"
               href="https://nerfies.github.io/">Nerfies</a>
             project page.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
// Simple carousel functionality
let currentSlides = {
  'wan-carousel': 0,
  'cog-carousel': 0,
  'freeinit-carousel': 0
};

function showSlide(carouselId, n) {
  const carousel = document.getElementById(carouselId);
  const items = carousel.querySelectorAll('.carousel-item');
  const totalSlides = items.length;
  
  if (n >= totalSlides) currentSlides[carouselId] = 0;
  if (n < 0) currentSlides[carouselId] = totalSlides - 1;
  
  items.forEach((item, index) => {
    item.style.display = index === currentSlides[carouselId] ? 'flex' : 'none';
  });
}

function nextSlide(carouselId) {
  currentSlides[carouselId]++;
  showSlide(carouselId, currentSlides[carouselId]);
}

function prevSlide(carouselId) {
  currentSlides[carouselId]--;
  showSlide(carouselId, currentSlides[carouselId]);
}

// Initialize carousels
document.addEventListener('DOMContentLoaded', function() {
  Object.keys(currentSlides).forEach(carouselId => {
    showSlide(carouselId, 0);
  });
});
</script>

</body>
</html>
